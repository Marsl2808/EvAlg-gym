{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd06a67657f0877f0054f0297e42be73e4e5bda1e39bebb74dea15ddd23ce218cf4",
   "display_name": "Python 3.8.10 64-bit ('ea_gym': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "df4b48496479b6dbac9f82cbbc0bc05dc03b6aa29290929ce28ee161e7111e9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dim. action space: (4,)\n",
      "Dim. observation space: (24,)\n",
      "--- Generation 0 ---\n",
      "INFO:root:max fitness: -26.880910549477008\n",
      "INFO:root:56 survived walker\n",
      "Time: 5.12 sec\n",
      "--- Generation 1 ---\n",
      "INFO:root:max fitness: -26.328674930249072\n",
      "INFO:root:52 survived walker\n",
      "Time: 3.04 sec\n",
      "--- Generation 2 ---\n",
      "INFO:root:max fitness: -26.328674930249072\n",
      "INFO:root:50 survived walker\n",
      "Time: 3.74 sec\n",
      "--- Generation 3 ---\n",
      "INFO:root:max fitness: -26.090524228402863\n",
      "INFO:root:52 survived walker\n",
      "Time: 3.43 sec\n",
      "--- Generation 4 ---\n",
      "INFO:root:max fitness: -25.01426265693427\n",
      "INFO:root:51 survived walker\n",
      "Time: 3.42 sec\n",
      "--- Generation 5 ---\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0d1e6e235749>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpop_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 \u001b[0magent_env_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# if generation % 100 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0d1e6e235749>\u001b[0m in \u001b[0;36magent_env_loop\u001b[1;34m(entity, generation)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_SEQUENCE_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# a_t, s_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# s_{t+1}, r_{t+1}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DEV\\Python\\EvAlg-gym\\src\\individuum\\neuralNet.py\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# TODO: layer specific activation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mlayer_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mlayer_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "from src.evolutionCtrl import Population_Manager\n",
    "from src.trainEval import TrainEval\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "# create gym Environment\n",
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "print(f\"Dim. action space: {env.action_space.shape}\")\n",
    "print(f\"Dim. observation space: {env.observation_space.shape}\")\n",
    "\n",
    "# training Params\n",
    "Const = {\n",
    "    'POP_SIZE': 100,\n",
    "    'MUTATION_RATE': .1,\n",
    "    'PROB_NODE_COPY': .1,\n",
    "    'N_PARENTS': 2,\n",
    "    'WEIGHT_INIT_INTERVAL': [-1.0, 1.0],\n",
    "    'N_LAYER_NODES': [env.observation_space.shape[0],\n",
    "                      35,\n",
    "                      env.action_space.shape[0]]\n",
    "}\n",
    "\n",
    "MAX_SEQUENCE_LEN = 400\n",
    "N_GENERATIONS = 2500\n",
    "\n",
    "pop_manager = Population_Manager(Const)\n",
    "\n",
    "train_evaluator = TrainEval()\n",
    "\n",
    "\n",
    "def agent_env_loop(entity, generation):\n",
    "    entity.survived = True\n",
    "    entity.fitness = 0\n",
    "    env.seed(10)\n",
    "    observation = env.reset()                                 # s_0\n",
    "\n",
    "    for i in range(MAX_SEQUENCE_LEN):\n",
    "\n",
    "        action = entity.controller.feed_forward(observation)  # a_t, s_t\n",
    "        observation, reward, done, _ = env.step(action)  # s_{t+1}, r_{t+1}\n",
    "\n",
    "        entity.fitness += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for generation in range(N_GENERATIONS):\n",
    "        t_start = time.time()\n",
    "\n",
    "        print(f\"--- Generation {generation} ---\")\n",
    "        for entity in pop_manager.population:\n",
    "            if not entity.survived:\n",
    "                agent_env_loop(entity, generation)\n",
    "\n",
    "        # if generation % 100 == 0:\n",
    "        #     train_evaluator.eval_training(pop_manager.population)\n",
    "\n",
    "        pop_manager.breed_new_population()\n",
    "\n",
    "        print(f\"Time: {(time.time() - t_start):.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# ---------- diversity measure\n",
    "# phenotype-based diversity measure (e.g. FFT of action sequence) vs. genotype based (hamming distance)\n",
    "# diversity = 0 ?\n",
    "\n",
    "# ---------- analyse\n",
    "# weight distribution analysis (e.g. 99 fitness solution compared to 72)\n",
    "\n",
    "# ---------- implementation\n",
    "# multiparent recombination\n",
    "# two child approach\n",
    "# one point crossover, n-point crossover, uniform crossover \n",
    "# generalization\n",
    "\n",
    "# ? aging\n",
    "# ? parameter noise\n",
    "# ? type checking\n",
    "# properties\n",
    "\n",
    "######################################################################################################################\n",
    "# POP_SIZE = 100\n",
    "# MAX_SEQUENCE_LEN = 400\n",
    "# N_GENERATIONS = 2000\n",
    "# MUTATION_RATE = .1\n",
    "# PROB_NODE_COPY = .1\n",
    "# WEIGHT_INIT_INTERVAL = [-1.0, 1.0]\n",
    "# WELFORD = False\n",
    "\n",
    "# 50 -> 99 fitness, 2000 gen\n",
    "# 48,48,32 -> 75 fitness\n",
    "# 32 -> 70, 2500 gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "56.074588818497155"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "pop_manager.population.sort(key=lambda x: x.fitness, reverse=True) \n",
    "best_agent = pop_manager.population[5]\n",
    "best_agent.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "57.91824195449292"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "env.seed(10) \n",
    "observation = env.reset()\n",
    "reward_test = .0\n",
    "obs_list = []\n",
    "for _ in range(MAX_SEQUENCE_LEN):\n",
    "    env.render()\n",
    "    action = best_agent.controller.feed_forward(observation)            # a_t, s_t            \n",
    "    observation, reward, done, _ = env.step(action)                     # s_{t+1}, r_{t+1}, a_t \n",
    "    obs_list.append(observation)\n",
    "    reward_test += reward\n",
    "env.close()\n",
    "reward_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i, weights in enumerate(best_agent.controller.weights):\n",
    "    np.savetxt(\"layer_\" + str(i), weights)\n",
    "    np.savetxt(\"bias_\" + str(i), best_agent.controller.bias[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testclass(object):\n",
    "    def __init__(self):\n",
    "        self.weights = [[1,2,3], [4,5,6]]\n",
    "\n",
    "x = testclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "y = x.weights[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "x.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = a\n",
    "b[0] = 4\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = np.random.uniform(-1.0, 1.0, (4, 3))\n",
    "weights_2 = np.random.uniform(-1.0, 1.0, (4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.13601143,  0.97048332, -0.8253675 ],\n",
       "       [ 0.72817677,  0.75721678,  0.75244338],\n",
       "       [-0.26970826, -0.59656433,  0.79409955],\n",
       "       [-0.86833561, -0.64606015, -0.6582288 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from difflib import SequenceMatcher as SequMatch\n",
    "\n",
    "rat = 0.0\n",
    "for i in range(len(weights)):\n",
    "    sm = SequMatch(None, weights[i].round(1), weights_2[i].round(1))\n",
    "    rat += sm.ratio()\n",
    "weights\n",
    "weights_2\n",
    "#rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.96191887, 0.5971491 , 0.52781256])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "np.random.uniform(low = -1.0, high = 1.0, size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "140703733913392"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "id(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1553873537200"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "id(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}